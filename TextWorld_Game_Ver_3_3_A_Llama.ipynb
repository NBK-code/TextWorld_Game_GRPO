{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NBK-code/TextWorld_Game_GRPO/blob/main/TextWorld_Game_Ver_3_3_A_Llama.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LmJVoXgKoyK"
      },
      "source": [
        "Data collection changed to align with stepwise optimization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eiMFlHJ2nPjc"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth vllm\n",
        "else:\n",
        "    # [NOTE] Do the below ONLY in Colab! Use [[pip install unsloth vllm]]\n",
        "    !pip install --no-deps unsloth vllm==0.8.5.post1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aVbjPvPn6nL"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth vllm\n",
        "else:\n",
        "    !pip install --no-deps unsloth vllm==0.8.5.post1\n",
        "    # [NOTE] Do the below ONLY in Colab! Use [[pip install unsloth vllm]]\n",
        "    # Skip restarting message in Colab\n",
        "    import sys, re, requests; modules = list(sys.modules.keys())\n",
        "    for x in modules: sys.modules.pop(x) if \"PIL\" in x or \"google\" in x else None\n",
        "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft \"trl==0.15.2\" triton cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf \"datasets>=3.4.1\" huggingface_hub hf_transfer\n",
        "    !pip install transformers==4.51.3\n",
        "\n",
        "    # vLLM requirements - vLLM breaks Colab due to reinstalling numpy\n",
        "    f = requests.get(\"https://raw.githubusercontent.com/vllm-project/vllm/refs/heads/main/requirements/common.txt\").content\n",
        "    with open(\"vllm_requirements.txt\", \"wb\") as file:\n",
        "        file.write(re.sub(rb\"(transformers|numpy|xformers)[^\\n]{1,}\\n\", b\"\", f))\n",
        "    !pip install -r vllm_requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWdB0zedWD6y",
        "outputId": "dd165d13-4a32-4c02-8060-ad9fd266eb79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/1.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ\u001b[0m \u001b[32m1.4/1.5 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m101.5/101.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for jericho (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
            "INFO 07-27 16:45:39 [importing.py:53] Triton module has been replaced with a placeholder.\n",
            "INFO 07-27 16:45:40 [__init__.py:239] Automatically detected platform cuda.\n"
          ]
        }
      ],
      "source": [
        "!pip install -q textworld\n",
        "import textworld\n",
        "import json\n",
        "from pathlib import Path\n",
        "from unsloth import FastLanguageModel\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ifQMDMEVn-ZZ"
      },
      "outputs": [],
      "source": [
        "max_seq_length = 1024  # Can increase for longer reasoning traces\n",
        "lora_rank = 8  # Larger rank = smarter, but slower\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=\"meta-llama/meta-Llama-3.1-8B-Instruct\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    load_in_4bit=True,  # False for LoRA 16bit\n",
        "    fast_inference=True,\n",
        "    max_lora_rank=lora_rank,\n",
        "    gpu_memory_utilization=0.6\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gwb7hz-6LXd"
      },
      "outputs": [],
      "source": [
        "def count_trainable_parameters(model):\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "\n",
        "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
        "    print(f\"Total parameters:     {total_params:,}\")\n",
        "    print(f\"Percentage trainable: {100 * trainable_params / total_params:.4f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjYBPrKuIHkV",
        "outputId": "d5dc53f0-fee2-4d65-cbe5-21af5479c098"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable parameters: 0\n",
            "Total parameters:     4,628,680,704\n",
            "Percentage trainable: 0.0000%\n"
          ]
        }
      ],
      "source": [
        "count_trainable_parameters(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbyPl8p3oAjY",
        "outputId": "2e0abb0a-c093-4dfe-bc64-551401a2d6ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2025.7.8 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = lora_rank, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\n",
        "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
        "    ], # Remove QKVO if out of memory\n",
        "    lora_alpha = lora_rank,\n",
        "    use_gradient_checkpointing = \"unsloth\", # Enable long context finetuning\n",
        "    random_state = 3407,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxOEWEJE6RRq",
        "outputId": "31b6be3b-e8cf-4e5e-faa8-6f05d379aa23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable parameters: 20,971,520\n",
            "Total parameters:     4,649,652,224\n",
            "Percentage trainable: 0.4510%\n"
          ]
        }
      ],
      "source": [
        "count_trainable_parameters(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NE27RZLLRG-"
      },
      "source": [
        "0.4510%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkevjzwyU4-Q",
        "outputId": "041932ca-f033-459b-9b79-e8fac6364645"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): LlamaForCausalLM(\n",
              "      (model): LlamaModel(\n",
              "        (embed_tokens): Embedding(128256, 4096, padding_idx=128004)\n",
              "        (layers): ModuleList(\n",
              "          (0): LlamaDecoderLayer(\n",
              "            (self_attn): LlamaAttention(\n",
              "              (q_proj): lora.Linear(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (k_proj): lora.Linear(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (v_proj): lora.Linear(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (o_proj): lora.Linear(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (rotary_emb): LlamaRotaryEmbedding()\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): lora.Linear(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=14336, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (up_proj): lora.Linear(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=14336, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (down_proj): lora.Linear(\n",
              "                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=14336, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "          )\n",
              "          (1): LlamaDecoderLayer(\n",
              "            (self_attn): LlamaAttention(\n",
              "              (q_proj): lora.Linear(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (k_proj): lora.Linear(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (v_proj): lora.Linear(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (o_proj): lora.Linear(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (rotary_emb): LlamaRotaryEmbedding()\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=4096, out_features=14336, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=14336, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (up_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=4096, out_features=14336, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=14336, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (down_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=14336, out_features=4096, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=14336, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "          )\n",
              "          (2-31): 30 x LlamaDecoderLayer(\n",
              "            (self_attn): LlamaAttention(\n",
              "              (q_proj): lora.Linear(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (k_proj): lora.Linear(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (v_proj): lora.Linear(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (o_proj): lora.Linear(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (rotary_emb): LlamaRotaryEmbedding()\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): lora.Linear(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=14336, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (up_proj): lora.Linear(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=14336, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (down_proj): lora.Linear(\n",
              "                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Identity()\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=14336, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "        (rotary_emb): LlamaRotaryEmbedding()\n",
              "      )\n",
              "      (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVLu-TAGoCuf"
      },
      "outputs": [],
      "source": [
        "system_message = \"\"\"\n",
        "You are playing a text-based adventure game in a world with various locations and items. Your goal is to explore the world and collect the hidden coin. You can move in different directions (e.g., north, south, east, west) and interact with objects and characters.\n",
        "\n",
        "### Game Rules:\n",
        "- You can move using: \"go north\", \"go south\", \"go east\", \"go west\".\n",
        "- When a coin is present, it will be clearly described.\n",
        "- Use \"take coin\" to collect it.\n",
        "- Do not return to rooms you've already visited unless necessary.\n",
        "\n",
        "### Objective:\n",
        "Your goal is to find the coin present somewhere in the environment. When you find the coin, you can claim it by using the command \"take coin\"\n",
        "\n",
        "### Response Format:\n",
        "<think> your reasoning goes here </think>\n",
        "<command> your next action goes here </command>\n",
        "\n",
        "Do not use any other format. Follow this structure exactly.\n",
        "\n",
        "### Example 1:\n",
        "Map So Far:\n",
        "Hallway: east ‚Üí Kitchen\n",
        "Kitchen: west ‚Üí Hallway\n",
        "\n",
        "Last Move:\n",
        "From Hallway ‚Üí go east ‚Üí Kitchen\n",
        "\n",
        "Current State:\n",
        "-= Kitchen =-\n",
        "You are in the Kitchen. There is no coin here. There are various utensils.\n",
        "\n",
        "You need an unblocked exit? You should try going west. You don't like doors? Why not try going north, that entranceway is unblocked.\n",
        "\n",
        "<think>I'm in the Kitchen. Using the \"Last Move\" and the \"Map So Far\", I see that I took east from Hallway to arrive here. If I go west I will just go back to the Hallway. But there was no coin in the Hallway. So I won't go back to the Hallway. I will try to explore other options. I see that I can go north. So I should take it.</think>\n",
        "<command>go north</command>\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vaPIt3U6ptlm"
      },
      "outputs": [],
      "source": [
        "def extract_initial_game_state(text):\n",
        "    \"\"\"\n",
        "    Extracts the initial room description and its name from the game start text.\n",
        "    \"\"\"\n",
        "    match = re.search(r'(-= .*? =-.*?)(?=>)', text, re.DOTALL)\n",
        "    if not match:\n",
        "        return None, None\n",
        "\n",
        "    description = match.group(1)\n",
        "    cleaned = re.sub(r'\\n\\s*\\n+', '\\n\\n', description.strip())\n",
        "\n",
        "    # Extract room name from -= Room =-\n",
        "    room_match = re.search(r\"-= (.*?) =-\", cleaned)\n",
        "    room_name = room_match.group(1).strip() if room_match else None\n",
        "\n",
        "    return cleaned, room_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3djp_iMvpv24"
      },
      "outputs": [],
      "source": [
        "def extract_thought_and_command(text):\n",
        "    \"\"\"\n",
        "    Extracts the first <think>...</think> block and <command>...</command> block from the given text.\n",
        "    Returns a tuple: (thought, command), where either can be None if not found.\n",
        "    \"\"\"\n",
        "    think_match = re.search(r\"<think>(.*?)</think>\", text, re.DOTALL)\n",
        "    command_match = re.search(r\"<command>(.*?)</command>\", text, re.DOTALL)\n",
        "\n",
        "    thought = think_match.group(1).strip() if think_match else None\n",
        "    command = command_match.group(1).strip() if command_match else None\n",
        "\n",
        "    return thought, command"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nV3Vnb82p6LX"
      },
      "outputs": [],
      "source": [
        "def parse_game_state(raw_text):\n",
        "    score_match = re.search(r\"<score>\\s*(\\d+)\\s*</score>\", raw_text)\n",
        "    score = int(score_match.group(1)) if score_match else 0 #fallback to 0\n",
        "\n",
        "    moves_match = re.search(r\"<moves>\\s*(\\d+)\\s*</moves>\", raw_text)\n",
        "    moves = int(moves_match.group(1)) if moves_match else 0\n",
        "\n",
        "    text = raw_text.split(\"<score>\")[0].strip()\n",
        "    state_description = re.sub(r'\\n\\s*\\n+', '\\n\\n', text.strip())\n",
        "\n",
        "    return state_description, score, moves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uskZ39yHqRXL"
      },
      "outputs": [],
      "source": [
        "def take_action(action: str):\n",
        "\n",
        "    state = env.step(action)\n",
        "    state_description, score, moves = parse_game_state(state[0]['raw'])\n",
        "\n",
        "    # Extract room name from state_description\n",
        "    room_match = re.search(r\"-= (.*?) =-\", state_description)\n",
        "    room_name = room_match.group(1).strip() if room_match else None\n",
        "\n",
        "    return state_description, score, moves, room_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxDFnF8tdx-4"
      },
      "outputs": [],
      "source": [
        "def format_room_graph(room_graph):\n",
        "    lines = [\"### Map So Far:\"]\n",
        "    for room, connections in room_graph.items():\n",
        "        edges = [f\"{dir} ‚Üí {dest}\" for dir, dest in connections.items()]\n",
        "        lines.append(f\"{room}: {', '.join(edges)}\")\n",
        "    return \"\\n\".join(lines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lgUNN7ssy8T"
      },
      "outputs": [],
      "source": [
        "def compute_completion_logprob_from_ids(full_input_ids, prompt_len, model):\n",
        "    \"\"\"\n",
        "    computes log-prob of tokens at i+1 given logits at i.\n",
        "    \"\"\"\n",
        "    attention_mask = torch.ones_like(full_input_ids)\n",
        "\n",
        "    logits = model(full_input_ids, attention_mask=attention_mask).logits  # shape (1, T, vocab)\n",
        "    log_probs = torch.nn.functional.log_softmax(logits[:, :-1, :], dim=-1)  # shape (1, T-1, vocab)\n",
        "\n",
        "    target_ids = full_input_ids[:, 1:]  # shape (1, T-1)\n",
        "    token_log_probs = log_probs.gather(2, target_ids.unsqueeze(-1)).squeeze(-1)  # shape (1, T-1)\n",
        "    token_log_probs = token_log_probs.squeeze(0)  # shape (T-1,)\n",
        "\n",
        "    completion_mask = torch.zeros_like(token_log_probs)\n",
        "    completion_mask[prompt_len - 1:] = 1.0  # offset by 1 due to shifting\n",
        "\n",
        "    completion_logprob = (token_log_probs * completion_mask).sum()\n",
        "\n",
        "    return completion_logprob, token_log_probs, completion_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xSRvkkeiFLK"
      },
      "outputs": [],
      "source": [
        "def run_episode(env, model, tokenizer, system_message, max_steps=20):\n",
        "    state = env.reset()\n",
        "    initial_game_state, prev_room = extract_initial_game_state(state.feedback)\n",
        "    user_message = initial_game_state\n",
        "\n",
        "    visited_room_names = set()\n",
        "    visited_room_names.add(prev_room)\n",
        "    room_graph = {}\n",
        "\n",
        "    logprobs = []\n",
        "    tokenwise_log_probs = []\n",
        "    moves = 0\n",
        "    score = 0\n",
        "\n",
        "    episode_full_input_ids = []\n",
        "    episode_prompt_len = []\n",
        "\n",
        "\n",
        "    for step in range(1, max_steps + 1):\n",
        "        prompt = tokenizer.apply_chat_template(\n",
        "            [\n",
        "                {\"role\": \"system\", \"content\": system_message},\n",
        "                {\"role\": \"user\", \"content\": user_message},\n",
        "            ],\n",
        "            tokenize=False,\n",
        "            add_generation_prompt=True)\n",
        "\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=200,\n",
        "                temperature=0.2,\n",
        "                do_sample=True,\n",
        "                pad_token_id=tokenizer.eos_token_id,\n",
        "            )\n",
        "\n",
        "        response = tokenizer.decode(\n",
        "            outputs[0][inputs[\"input_ids\"].shape[-1]:], skip_special_tokens=True)\n",
        "\n",
        "        #print(f\"ü§ñ Response: {response}\")\n",
        "\n",
        "        # Get prompt length and full sequence\n",
        "        prompt_len = inputs[\"input_ids\"].shape[1]\n",
        "        full_input_ids = outputs[0].unsqueeze(0)  # shape (1, T)\n",
        "\n",
        "        # Compute log-probs on completion portion\n",
        "        with torch.no_grad():\n",
        "            completion_logprob, token_log_probs, completion_mask = compute_completion_logprob_from_ids(\n",
        "                                                  full_input_ids, prompt_len, model)\n",
        "\n",
        "        episode_full_input_ids.append(full_input_ids)\n",
        "        episode_prompt_len.append(prompt_len)\n",
        "        logprobs.append(completion_logprob)\n",
        "        tokenwise_log_probs.append(token_log_probs)\n",
        "\n",
        "        thought, action = extract_thought_and_command(response)\n",
        "        if not action:\n",
        "            print(\"\\n No valid command generated. Ending episode.\")\n",
        "            step = max_steps\n",
        "            break\n",
        "\n",
        "        state, maybe_score, moves, next_room = take_action(action)\n",
        "\n",
        "        if maybe_score is not None:\n",
        "            score = maybe_score\n",
        "\n",
        "        if score == 1:\n",
        "            print(\"Coin Found!\")\n",
        "            break\n",
        "\n",
        "        # Map tracking\n",
        "        if next_room and next_room not in visited_room_names:\n",
        "            visited_room_names.add(next_room)\n",
        "\n",
        "        normalized_action = action.lower()\n",
        "        if prev_room and next_room and normalized_action.startswith(\"go \"):\n",
        "            direction = normalized_action.split()[1]\n",
        "            room_graph.setdefault(prev_room, {})[direction] = next_room\n",
        "            reverse = {\"north\": \"south\", \"south\": \"north\", \"east\": \"west\", \"west\": \"east\"}\n",
        "            rev_dir = reverse.get(direction)\n",
        "            if rev_dir:\n",
        "                room_graph.setdefault(next_room, {})[rev_dir] = prev_room\n",
        "\n",
        "        graph_summary = format_room_graph(room_graph)\n",
        "        last_move_description = f\"From {prev_room} ‚Üí {action.lower()} ‚Üí {next_room}\"\n",
        "        user_message = (\n",
        "            f\"{graph_summary}\\n\\n\"\n",
        "            f\"### Last Move:\\n{last_move_description}\\n\\n\"\n",
        "            f\"### Current State:\\n{state}\\n\\n\"\n",
        "            f\"---\\n\\n\"\n",
        "            f\"### Please respond strictly in the following format:\\n\\n\"\n",
        "            f\"<think>...</think>\\n<command>...</command>\"\n",
        "        )\n",
        "\n",
        "        prev_room = next_room\n",
        "\n",
        "    reward = score - 0.01 * step\n",
        "    return logprobs, tokenwise_log_probs, reward, episode_full_input_ids, episode_prompt_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0da7yUw432Y"
      },
      "outputs": [],
      "source": [
        "def collect_episodes(env, model, tokenizer, system_message, N=8):\n",
        "    all_logprobs = []\n",
        "    all_tokenwise_log_probs = []\n",
        "    all_rewards = []\n",
        "    all_full_input_ids = []\n",
        "    all_prompt_len = []\n",
        "\n",
        "    for i in range(N):\n",
        "        print(f\"\\nüéÆ Episode {i + 1} / {N}\")\n",
        "        logprobs, tokenwise_log_probs, reward, full_input_ids, prompt_len = run_episode(env, model, tokenizer, system_message)\n",
        "        all_logprobs.append(logprobs)\n",
        "        all_tokenwise_log_probs.append(tokenwise_log_probs)\n",
        "        all_rewards.append(reward)\n",
        "        all_full_input_ids.append(full_input_ids)\n",
        "        all_prompt_len.append(prompt_len)\n",
        "        print(f\"‚úÖ Reward: {reward:.4f} | Steps: {len(logprobs)}\")\n",
        "\n",
        "    return all_logprobs, all_tokenwise_log_probs, all_rewards, all_full_input_ids, all_prompt_len"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_advantages(all_rewards):\n",
        "\n",
        "    rewards = torch.tensor(all_rewards, dtype=torch.float32)\n",
        "    mean_r = rewards.mean()\n",
        "    std_r = rewards.std(unbiased=False) + 1e-8  # unbiased=True by default\n",
        "    advantages = (rewards - mean_r) / std_r\n",
        "    return advantages.tolist(), mean_r"
      ],
      "metadata": {
        "id": "WCSsuoRRHsLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DudawQ_1V1CI"
      },
      "outputs": [],
      "source": [
        "# ------------------ Configs ------------------\n",
        "levels = [5, 6, 7]\n",
        "seeds = [10, 14, 18, 22, 26, 30, 34, 38, 42, 46]  # 10 seeds\n",
        "episodes_per_game = 8\n",
        "\n",
        "save_dir = Path(\"grpo_dataset\")\n",
        "save_dir.mkdir(exist_ok=True)\n",
        "save_path = save_dir / \"grpo_data.jsonl\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ybXPVRuJyFu",
        "outputId": "005b6f9f-abcd-4cd6-d446-730b30f87e36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "----- üåç Level: 5 | Seed: 10 -----\n",
            "\n",
            "üéÆ Episode 1 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8100 | Steps: 19\n",
            "\n",
            "üéÆ Episode 2 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9300 | Steps: 7\n",
            "\n",
            "üéÆ Episode 3 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 4 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9500 | Steps: 5\n",
            "\n",
            "üéÆ Episode 5 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9500 | Steps: 5\n",
            "\n",
            "üéÆ Episode 6 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9500 | Steps: 5\n",
            "\n",
            "üéÆ Episode 7 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9500 | Steps: 5\n",
            "\n",
            "üéÆ Episode 8 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9500 | Steps: 5\n",
            "\n",
            "üåç Level: 5 | Seed: 10 | Mean reward: 0.7862\n",
            "\n",
            "----- üåç Level: 5 | Seed: 14 -----\n",
            "\n",
            "üéÆ Episode 1 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9300 | Steps: 7\n",
            "\n",
            "üéÆ Episode 2 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8800 | Steps: 12\n",
            "\n",
            "üéÆ Episode 3 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9500 | Steps: 5\n",
            "\n",
            "üéÆ Episode 4 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9500 | Steps: 5\n",
            "\n",
            "üéÆ Episode 5 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8700 | Steps: 13\n",
            "\n",
            "üéÆ Episode 6 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8500 | Steps: 15\n",
            "\n",
            "üéÆ Episode 7 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8600 | Steps: 14\n",
            "\n",
            "üéÆ Episode 8 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9500 | Steps: 5\n",
            "\n",
            "üåç Level: 5 | Seed: 14 | Mean reward: 0.9050\n",
            "\n",
            "----- üåç Level: 5 | Seed: 18 -----\n",
            "\n",
            "üéÆ Episode 1 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9500 | Steps: 5\n",
            "\n",
            "üéÆ Episode 2 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9500 | Steps: 5\n",
            "\n",
            "üéÆ Episode 3 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9500 | Steps: 5\n",
            "\n",
            "üéÆ Episode 4 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8800 | Steps: 12\n",
            "\n",
            "üéÆ Episode 5 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9300 | Steps: 7\n",
            "\n",
            "üéÆ Episode 6 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9300 | Steps: 7\n",
            "\n",
            "üéÆ Episode 7 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8500 | Steps: 15\n",
            "\n",
            "üéÆ Episode 8 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9500 | Steps: 5\n",
            "\n",
            "üåç Level: 5 | Seed: 18 | Mean reward: 0.9237\n",
            "\n",
            "----- üåç Level: 5 | Seed: 22 -----\n",
            "\n",
            "üéÆ Episode 1 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 2 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 3 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9300 | Steps: 7\n",
            "\n",
            "üéÆ Episode 4 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 5 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8500 | Steps: 15\n",
            "\n",
            "üéÆ Episode 6 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 7 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8900 | Steps: 11\n",
            "\n",
            "üéÆ Episode 8 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9200 | Steps: 8\n",
            "\n",
            "üåç Level: 5 | Seed: 22 | Mean reward: 0.4737\n",
            "\n",
            "----- üåç Level: 5 | Seed: 26 -----\n",
            "\n",
            "üéÆ Episode 1 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9500 | Steps: 5\n",
            "\n",
            "üéÆ Episode 2 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9400 | Steps: 6\n",
            "\n",
            "üéÆ Episode 3 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9500 | Steps: 5\n",
            "\n",
            "üéÆ Episode 4 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9500 | Steps: 5\n",
            "\n",
            "üéÆ Episode 5 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 6 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8700 | Steps: 13\n",
            "\n",
            "üéÆ Episode 7 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9200 | Steps: 8\n",
            "\n",
            "üéÆ Episode 8 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9500 | Steps: 5\n",
            "\n",
            "üåç Level: 5 | Seed: 26 | Mean reward: 0.7912\n",
            "\n",
            "----- üåç Level: 5 | Seed: 30 -----\n",
            "\n",
            "üéÆ Episode 1 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9300 | Steps: 7\n",
            "\n",
            "üéÆ Episode 2 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9300 | Steps: 7\n",
            "\n",
            "üéÆ Episode 3 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8300 | Steps: 17\n",
            "\n",
            "üéÆ Episode 4 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9100 | Steps: 9\n",
            "\n",
            "üéÆ Episode 5 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9100 | Steps: 9\n",
            "\n",
            "üéÆ Episode 6 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9500 | Steps: 5\n",
            "\n",
            "üéÆ Episode 7 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 8 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9500 | Steps: 5\n",
            "\n",
            "üåç Level: 5 | Seed: 30 | Mean reward: 0.7763\n",
            "\n",
            "----- üåç Level: 5 | Seed: 34 -----\n",
            "\n",
            "üéÆ Episode 1 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9500 | Steps: 5\n",
            "\n",
            "üéÆ Episode 2 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9500 | Steps: 5\n",
            "\n",
            "üéÆ Episode 3 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8900 | Steps: 11\n",
            "\n",
            "üéÆ Episode 4 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9500 | Steps: 5\n",
            "\n",
            "üéÆ Episode 5 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9500 | Steps: 5\n",
            "\n",
            "üéÆ Episode 6 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 7 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9500 | Steps: 5\n",
            "\n",
            "üéÆ Episode 8 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8800 | Steps: 12\n",
            "\n",
            "üåç Level: 5 | Seed: 34 | Mean reward: 0.7900\n",
            "\n",
            "----- üåç Level: 5 | Seed: 38 -----\n",
            "\n",
            "üéÆ Episode 1 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9500 | Steps: 5\n",
            "\n",
            "üéÆ Episode 2 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9300 | Steps: 7\n",
            "\n",
            "üéÆ Episode 3 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8800 | Steps: 12\n",
            "\n",
            "üéÆ Episode 4 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9300 | Steps: 7\n",
            "\n",
            "üéÆ Episode 5 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9500 | Steps: 5\n",
            "\n",
            "üéÆ Episode 6 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9000 | Steps: 10\n",
            "\n",
            "üéÆ Episode 7 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8100 | Steps: 19\n",
            "\n",
            "üéÆ Episode 8 / 8\n",
            "\n",
            " No valid command generated. Ending episode.\n",
            "‚úÖ Reward: -0.2000 | Steps: 5\n",
            "\n",
            "üåç Level: 5 | Seed: 38 | Mean reward: 0.7688\n",
            "\n",
            "----- üåç Level: 5 | Seed: 42 -----\n",
            "\n",
            "üéÆ Episode 1 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9400 | Steps: 6\n",
            "\n",
            "üéÆ Episode 2 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8400 | Steps: 16\n",
            "\n",
            "üéÆ Episode 3 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9500 | Steps: 5\n",
            "\n",
            "üéÆ Episode 4 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 5 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 6 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 7 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8500 | Steps: 15\n",
            "\n",
            "üéÆ Episode 8 / 8\n",
            "\n",
            " No valid command generated. Ending episode.\n",
            "‚úÖ Reward: -0.2000 | Steps: 6\n",
            "\n",
            "üåç Level: 5 | Seed: 42 | Mean reward: 0.3475\n",
            "\n",
            "----- üåç Level: 5 | Seed: 46 -----\n",
            "\n",
            "üéÆ Episode 1 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9500 | Steps: 5\n",
            "\n",
            "üéÆ Episode 2 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 3 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9500 | Steps: 5\n",
            "\n",
            "üéÆ Episode 4 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9500 | Steps: 5\n",
            "\n",
            "üéÆ Episode 5 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9500 | Steps: 5\n",
            "\n",
            "üéÆ Episode 6 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9500 | Steps: 5\n",
            "\n",
            "üéÆ Episode 7 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8400 | Steps: 16\n",
            "\n",
            "üéÆ Episode 8 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üåç Level: 5 | Seed: 46 | Mean reward: 0.6488\n",
            "\n",
            "----- üåç Level: 6 | Seed: 10 -----\n",
            "\n",
            "üéÆ Episode 1 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 2 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 3 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 4 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9400 | Steps: 6\n",
            "\n",
            "üéÆ Episode 5 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8500 | Steps: 15\n",
            "\n",
            "üéÆ Episode 6 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 7 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 8 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9100 | Steps: 9\n",
            "\n",
            "üåç Level: 6 | Seed: 10 | Mean reward: 0.2125\n",
            "\n",
            "----- üåç Level: 6 | Seed: 14 -----\n",
            "\n",
            "üéÆ Episode 1 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9400 | Steps: 6\n",
            "\n",
            "üéÆ Episode 2 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9400 | Steps: 6\n",
            "\n",
            "üéÆ Episode 3 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9200 | Steps: 8\n",
            "\n",
            "üéÆ Episode 4 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9400 | Steps: 6\n",
            "\n",
            "üéÆ Episode 5 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8300 | Steps: 17\n",
            "\n",
            "üéÆ Episode 6 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9100 | Steps: 9\n",
            "\n",
            "üéÆ Episode 7 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9200 | Steps: 8\n",
            "\n",
            "üéÆ Episode 8 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8800 | Steps: 12\n",
            "\n",
            "üåç Level: 6 | Seed: 14 | Mean reward: 0.9100\n",
            "\n",
            "----- üåç Level: 6 | Seed: 18 -----\n",
            "\n",
            "üéÆ Episode 1 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9400 | Steps: 6\n",
            "\n",
            "üéÆ Episode 2 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9400 | Steps: 6\n",
            "\n",
            "üéÆ Episode 3 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 4 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 5 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8100 | Steps: 19\n",
            "\n",
            "üéÆ Episode 6 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9400 | Steps: 6\n",
            "\n",
            "üéÆ Episode 7 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9400 | Steps: 6\n",
            "\n",
            "üéÆ Episode 8 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9400 | Steps: 6\n",
            "\n",
            "üåç Level: 6 | Seed: 18 | Mean reward: 0.6388\n",
            "\n",
            "----- üåç Level: 6 | Seed: 22 -----\n",
            "\n",
            "üéÆ Episode 1 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 2 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 3 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 4 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8200 | Steps: 18\n",
            "\n",
            "üéÆ Episode 5 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 6 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 7 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 8 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8300 | Steps: 17\n",
            "\n",
            "üåç Level: 6 | Seed: 22 | Mean reward: 0.0562\n",
            "\n",
            "----- üåç Level: 6 | Seed: 26 -----\n",
            "\n",
            "üéÆ Episode 1 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8200 | Steps: 18\n",
            "\n",
            "üéÆ Episode 2 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8800 | Steps: 12\n",
            "\n",
            "üéÆ Episode 3 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9400 | Steps: 6\n",
            "\n",
            "üéÆ Episode 4 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 5 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9300 | Steps: 7\n",
            "\n",
            "üéÆ Episode 6 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 7 / 8\n",
            "\n",
            " No valid command generated. Ending episode.\n",
            "‚úÖ Reward: -0.2000 | Steps: 15\n",
            "\n",
            "üéÆ Episode 8 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8300 | Steps: 17\n",
            "\n",
            "üåç Level: 6 | Seed: 26 | Mean reward: 0.4750\n",
            "\n",
            "----- üåç Level: 6 | Seed: 30 -----\n",
            "\n",
            "üéÆ Episode 1 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8400 | Steps: 16\n",
            "\n",
            "üéÆ Episode 2 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 3 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8500 | Steps: 15\n",
            "\n",
            "üéÆ Episode 4 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9000 | Steps: 10\n",
            "\n",
            "üéÆ Episode 5 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8800 | Steps: 12\n",
            "\n",
            "üéÆ Episode 6 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8600 | Steps: 14\n",
            "\n",
            "üéÆ Episode 7 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8500 | Steps: 15\n",
            "\n",
            "üéÆ Episode 8 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üåç Level: 6 | Seed: 30 | Mean reward: 0.5975\n",
            "\n",
            "----- üåç Level: 6 | Seed: 34 -----\n",
            "\n",
            "üéÆ Episode 1 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9400 | Steps: 6\n",
            "\n",
            "üéÆ Episode 2 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9400 | Steps: 6\n",
            "\n",
            "üéÆ Episode 3 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8600 | Steps: 14\n",
            "\n",
            "üéÆ Episode 4 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9300 | Steps: 7\n",
            "\n",
            "üéÆ Episode 5 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9400 | Steps: 6\n",
            "\n",
            "üéÆ Episode 6 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8900 | Steps: 11\n",
            "\n",
            "üéÆ Episode 7 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9400 | Steps: 6\n",
            "\n",
            "üéÆ Episode 8 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9000 | Steps: 10\n",
            "\n",
            "üåç Level: 6 | Seed: 34 | Mean reward: 0.9175\n",
            "\n",
            "----- üåç Level: 6 | Seed: 38 -----\n",
            "\n",
            "üéÆ Episode 1 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9400 | Steps: 6\n",
            "\n",
            "üéÆ Episode 2 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8900 | Steps: 11\n",
            "\n",
            "üéÆ Episode 3 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 4 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 5 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9400 | Steps: 6\n",
            "\n",
            "üéÆ Episode 6 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8700 | Steps: 13\n",
            "\n",
            "üéÆ Episode 7 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9400 | Steps: 6\n",
            "\n",
            "üéÆ Episode 8 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8700 | Steps: 13\n",
            "\n",
            "üåç Level: 6 | Seed: 38 | Mean reward: 0.6312\n",
            "\n",
            "----- üåç Level: 6 | Seed: 42 -----\n",
            "\n",
            "üéÆ Episode 1 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8200 | Steps: 18\n",
            "\n",
            "üéÆ Episode 2 / 8\n",
            "\n",
            " No valid command generated. Ending episode.\n",
            "‚úÖ Reward: -0.2000 | Steps: 11\n",
            "\n",
            "üéÆ Episode 3 / 8\n",
            "\n",
            " No valid command generated. Ending episode.\n",
            "‚úÖ Reward: -0.2000 | Steps: 8\n",
            "\n",
            "üéÆ Episode 4 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 5 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9400 | Steps: 6\n",
            "\n",
            "üéÆ Episode 6 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 7 / 8\n",
            "\n",
            " No valid command generated. Ending episode.\n",
            "‚úÖ Reward: -0.2000 | Steps: 8\n",
            "\n",
            "üéÆ Episode 8 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8700 | Steps: 13\n",
            "\n",
            "üåç Level: 6 | Seed: 42 | Mean reward: 0.2037\n",
            "\n",
            "----- üåç Level: 6 | Seed: 46 -----\n",
            "\n",
            "üéÆ Episode 1 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8800 | Steps: 12\n",
            "\n",
            "üéÆ Episode 2 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8800 | Steps: 12\n",
            "\n",
            "üéÆ Episode 3 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9400 | Steps: 6\n",
            "\n",
            "üéÆ Episode 4 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9400 | Steps: 6\n",
            "\n",
            "üéÆ Episode 5 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9400 | Steps: 6\n",
            "\n",
            "üéÆ Episode 6 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9300 | Steps: 7\n",
            "\n",
            "üéÆ Episode 7 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9400 | Steps: 6\n",
            "\n",
            "üéÆ Episode 8 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9400 | Steps: 6\n",
            "\n",
            "üåç Level: 6 | Seed: 46 | Mean reward: 0.9237\n",
            "\n",
            "----- üåç Level: 7 | Seed: 10 -----\n",
            "\n",
            "üéÆ Episode 1 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 2 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 3 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8200 | Steps: 18\n",
            "\n",
            "üéÆ Episode 4 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9000 | Steps: 10\n",
            "\n",
            "üéÆ Episode 5 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 6 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9000 | Steps: 10\n",
            "\n",
            "üéÆ Episode 7 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9300 | Steps: 7\n",
            "\n",
            "üéÆ Episode 8 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9300 | Steps: 7\n",
            "\n",
            "üåç Level: 7 | Seed: 10 | Mean reward: 0.4850\n",
            "\n",
            "----- üåç Level: 7 | Seed: 14 -----\n",
            "\n",
            "üéÆ Episode 1 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 2 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9300 | Steps: 7\n",
            "\n",
            "üéÆ Episode 3 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8900 | Steps: 11\n",
            "\n",
            "üéÆ Episode 4 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8700 | Steps: 13\n",
            "\n",
            "üéÆ Episode 5 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 6 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 7 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 8 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üåç Level: 7 | Seed: 14 | Mean reward: 0.2112\n",
            "\n",
            "----- üåç Level: 7 | Seed: 18 -----\n",
            "\n",
            "üéÆ Episode 1 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 2 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8600 | Steps: 14\n",
            "\n",
            "üéÆ Episode 3 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9100 | Steps: 9\n",
            "\n",
            "üéÆ Episode 4 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9100 | Steps: 9\n",
            "\n",
            "üéÆ Episode 5 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 6 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9300 | Steps: 7\n",
            "\n",
            "üéÆ Episode 7 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 8 / 8\n",
            "\n",
            " No valid command generated. Ending episode.\n",
            "‚úÖ Reward: -0.2000 | Steps: 19\n",
            "\n",
            "üåç Level: 7 | Seed: 18 | Mean reward: 0.3512\n",
            "\n",
            "----- üåç Level: 7 | Seed: 22 -----\n",
            "\n",
            "üéÆ Episode 1 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 2 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 3 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 4 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 5 / 8\n",
            "\n",
            " No valid command generated. Ending episode.\n",
            "‚úÖ Reward: -0.2000 | Steps: 7\n",
            "\n",
            "üéÆ Episode 6 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 7 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 8 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üåç Level: 7 | Seed: 22 | Mean reward: -0.2000\n",
            "\n",
            "----- üåç Level: 7 | Seed: 26 -----\n",
            "\n",
            "üéÆ Episode 1 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 2 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 3 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 4 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 5 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 6 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9300 | Steps: 7\n",
            "\n",
            "üéÆ Episode 7 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8800 | Steps: 12\n",
            "\n",
            "üéÆ Episode 8 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üåç Level: 7 | Seed: 26 | Mean reward: 0.0763\n",
            "\n",
            "----- üåç Level: 7 | Seed: 30 -----\n",
            "\n",
            "üéÆ Episode 1 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8800 | Steps: 12\n",
            "\n",
            "üéÆ Episode 2 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8900 | Steps: 11\n",
            "\n",
            "üéÆ Episode 3 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8400 | Steps: 16\n",
            "\n",
            "üéÆ Episode 4 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 5 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8700 | Steps: 13\n",
            "\n",
            "üéÆ Episode 6 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 7 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 8 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üåç Level: 7 | Seed: 30 | Mean reward: 0.3350\n",
            "\n",
            "----- üåç Level: 7 | Seed: 34 -----\n",
            "\n",
            "üéÆ Episode 1 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9100 | Steps: 9\n",
            "\n",
            "üéÆ Episode 2 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9300 | Steps: 7\n",
            "\n",
            "üéÆ Episode 3 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8400 | Steps: 16\n",
            "\n",
            "üéÆ Episode 4 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9300 | Steps: 7\n",
            "\n",
            "üéÆ Episode 5 / 8\n",
            "\n",
            " No valid command generated. Ending episode.\n",
            "‚úÖ Reward: -0.2000 | Steps: 17\n",
            "\n",
            "üéÆ Episode 6 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 7 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 8 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9000 | Steps: 10\n",
            "\n",
            "üåç Level: 7 | Seed: 34 | Mean reward: 0.6138\n",
            "\n",
            "----- üåç Level: 7 | Seed: 38 -----\n",
            "\n",
            "üéÆ Episode 1 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 2 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 3 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 4 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8800 | Steps: 12\n",
            "\n",
            "üéÆ Episode 5 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 6 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 7 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 8 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üåç Level: 7 | Seed: 38 | Mean reward: -0.0650\n",
            "\n",
            "----- üåç Level: 7 | Seed: 42 -----\n",
            "\n",
            "üéÆ Episode 1 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 2 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 3 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 4 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 5 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 6 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üéÆ Episode 7 / 8\n",
            "\n",
            " No valid command generated. Ending episode.\n",
            "‚úÖ Reward: -0.2000 | Steps: 11\n",
            "\n",
            "üéÆ Episode 8 / 8\n",
            "‚úÖ Reward: -0.2000 | Steps: 20\n",
            "\n",
            "üåç Level: 7 | Seed: 42 | Mean reward: -0.2000\n",
            "\n",
            "----- üåç Level: 7 | Seed: 46 -----\n",
            "\n",
            "üéÆ Episode 1 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9100 | Steps: 9\n",
            "\n",
            "üéÆ Episode 2 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9300 | Steps: 7\n",
            "\n",
            "üéÆ Episode 3 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8900 | Steps: 11\n",
            "\n",
            "üéÆ Episode 4 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9300 | Steps: 7\n",
            "\n",
            "üéÆ Episode 5 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8300 | Steps: 17\n",
            "\n",
            "üéÆ Episode 6 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9300 | Steps: 7\n",
            "\n",
            "üéÆ Episode 7 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.8700 | Steps: 13\n",
            "\n",
            "üéÆ Episode 8 / 8\n",
            "Coin Found!\n",
            "‚úÖ Reward: 0.9200 | Steps: 8\n",
            "\n",
            "üåç Level: 7 | Seed: 46 | Mean reward: 0.9013\n",
            "\n",
            "‚úÖ All data saved to: grpo_dataset/grpo_data.jsonl\n"
          ]
        }
      ],
      "source": [
        "with open(save_path, \"w\") as f:\n",
        "    for level in levels:\n",
        "        for seed in seeds:\n",
        "            gamefile = f\"coin_level{level}_{seed}.z8\"\n",
        "            !tw-make tw-coin_collector --level {level} --seed {seed} --output {gamefile} --silent\n",
        "            env = textworld.start(gamefile)\n",
        "            print(f\"\\n----- üåç Level: {level} | Seed: {seed} -----\")\n",
        "\n",
        "            # Get N rollouts for this environment\n",
        "            all_logprobs, all_tokenwise_log_probs, all_rewards, all_full_input_ids, all_prompt_len = collect_episodes(\n",
        "                env, model, tokenizer, system_message, episodes_per_game)\n",
        "\n",
        "            # Compute advantage across all episodes\n",
        "            all_advantages, mean_reward = compute_advantages(all_rewards)  # same length as episodes_per_game\n",
        "\n",
        "            # Save one JSONL line per step\n",
        "            for i in range(episodes_per_game):\n",
        "                for step in range(len(all_full_input_ids[i])):\n",
        "                    example = {\n",
        "                        \"level\": level,\n",
        "                        \"seed\": seed,\n",
        "                        \"episode\": i,\n",
        "                        \"step\": step,\n",
        "                        \"input_ids\": all_full_input_ids[i][step].squeeze(0).tolist(),\n",
        "                        \"prompt_len\": all_prompt_len[i][step],\n",
        "                        \"logprob_old\": all_logprobs[i][step].item(),\n",
        "                        \"tokenwise_logprobs\": all_tokenwise_log_probs[i][step].tolist(),\n",
        "                        \"advantage\": all_advantages[i],\n",
        "                        \"reward\": all_rewards[i],\n",
        "                        \"mean_reward\": mean_reward.item(),\n",
        "                    }\n",
        "                    f.write(json.dumps(example) + \"\\n\")\n",
        "\n",
        "            print(f\"\\nüåç Level: {level} | Seed: {seed} | Mean reward: {mean_reward:.4f}\")\n",
        "\n",
        "\n",
        "print(f\"\\n‚úÖ All data saved to: {save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1ShdztJwgxl9",
        "outputId": "93186dfd-1d65-47b5-cbb0-b34afd34894c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   level  seed  episode  step  \\\n",
              "0      5    10        0     0   \n",
              "1      5    10        0     1   \n",
              "2      5    10        0     2   \n",
              "3      5    10        0     3   \n",
              "4      5    10        0     4   \n",
              "\n",
              "                                           input_ids  prompt_len  logprob_old  \\\n",
              "0  [128000, 128000, 128006, 9125, 128007, 271, 38...         452   -29.546875   \n",
              "1  [128000, 128000, 128006, 9125, 128007, 271, 38...         526   -36.250000   \n",
              "2  [128000, 128000, 128006, 9125, 128007, 271, 38...         514   -49.125000   \n",
              "3  [128000, 128000, 128006, 9125, 128007, 271, 38...         485   -47.437500   \n",
              "4  [128000, 128000, 128006, 9125, 128007, 271, 38...         484   -33.718750   \n",
              "\n",
              "                                  tokenwise_logprobs  advantage  reward  \\\n",
              "0  [-13.6953125, -4.18359375, -22.375, -12.671875...    0.06325    0.81   \n",
              "1  [-13.6953125, -4.18359375, -22.375, -12.671875...    0.06325    0.81   \n",
              "2  [-13.6953125, -4.18359375, -22.375, -12.671875...    0.06325    0.81   \n",
              "3  [-13.6953125, -4.18359375, -22.375, -12.671875...    0.06325    0.81   \n",
              "4  [-13.6953125, -4.18359375, -22.375, -12.671875...    0.06325    0.81   \n",
              "\n",
              "   mean_reward  \n",
              "0      0.78625  \n",
              "1      0.78625  \n",
              "2      0.78625  \n",
              "3      0.78625  \n",
              "4      0.78625  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f3478eac-8695-42f3-8e41-4e983176c20d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>level</th>\n",
              "      <th>seed</th>\n",
              "      <th>episode</th>\n",
              "      <th>step</th>\n",
              "      <th>input_ids</th>\n",
              "      <th>prompt_len</th>\n",
              "      <th>logprob_old</th>\n",
              "      <th>tokenwise_logprobs</th>\n",
              "      <th>advantage</th>\n",
              "      <th>reward</th>\n",
              "      <th>mean_reward</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[128000, 128000, 128006, 9125, 128007, 271, 38...</td>\n",
              "      <td>452</td>\n",
              "      <td>-29.546875</td>\n",
              "      <td>[-13.6953125, -4.18359375, -22.375, -12.671875...</td>\n",
              "      <td>0.06325</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.78625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[128000, 128000, 128006, 9125, 128007, 271, 38...</td>\n",
              "      <td>526</td>\n",
              "      <td>-36.250000</td>\n",
              "      <td>[-13.6953125, -4.18359375, -22.375, -12.671875...</td>\n",
              "      <td>0.06325</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.78625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>[128000, 128000, 128006, 9125, 128007, 271, 38...</td>\n",
              "      <td>514</td>\n",
              "      <td>-49.125000</td>\n",
              "      <td>[-13.6953125, -4.18359375, -22.375, -12.671875...</td>\n",
              "      <td>0.06325</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.78625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>[128000, 128000, 128006, 9125, 128007, 271, 38...</td>\n",
              "      <td>485</td>\n",
              "      <td>-47.437500</td>\n",
              "      <td>[-13.6953125, -4.18359375, -22.375, -12.671875...</td>\n",
              "      <td>0.06325</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.78625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>[128000, 128000, 128006, 9125, 128007, 271, 38...</td>\n",
              "      <td>484</td>\n",
              "      <td>-33.718750</td>\n",
              "      <td>[-13.6953125, -4.18359375, -22.375, -12.671875...</td>\n",
              "      <td>0.06325</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.78625</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f3478eac-8695-42f3-8e41-4e983176c20d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f3478eac-8695-42f3-8e41-4e983176c20d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f3478eac-8695-42f3-8e41-4e983176c20d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-03653cf7-f14d-4ed4-9e25-8c23c308b95c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-03653cf7-f14d-4ed4-9e25-8c23c308b95c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-03653cf7-f14d-4ed4-9e25-8c23c308b95c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3078,\n  \"fields\": [\n    {\n      \"column\": \"level\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 5,\n        \"max\": 7,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          5,\n          6,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"seed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11,\n        \"min\": 10,\n        \"max\": 46,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          42,\n          14,\n          30\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"episode\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 7,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1,\n          5,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"step\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 0,\n        \"max\": 19,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0,\n          17,\n          15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"input_ids\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prompt_len\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 37,\n        \"min\": 443,\n        \"max\": 611,\n        \"num_unique_values\": 140,\n        \"samples\": [\n          581,\n          546,\n          536\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"logprob_old\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11.066665694695905,\n        \"min\": -99.5625,\n        \"max\": -14.8203125,\n        \"num_unique_values\": 1336,\n        \"samples\": [\n          -54.6875,\n          -25.953125,\n          -25.765625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokenwise_logprobs\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"advantage\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0246050621485303,\n        \"min\": -2.639479398727417,\n        \"max\": 2.645751237869262,\n        \"num_unique_values\": 126,\n        \"samples\": [\n          0.613089978694915,\n          0.8528305292129511,\n          0.39485055208206105\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reward\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5432178119834656,\n        \"min\": -0.2,\n        \"max\": 0.9500000000000001,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          0.81,\n          0.929999999999999,\n          0.87\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_reward\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.34887998542128074,\n        \"min\": -0.20000001788139302,\n        \"max\": 0.923749983310699,\n        \"num_unique_values\": 29,\n        \"samples\": [\n          -0.065000005066394,\n          0.9175000190734861,\n          0.6387500166893001\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "import pandas as pd\n",
        "file_path = \"/content/grpo_dataset/grpo_data.jsonl\"\n",
        "df = pd.read_json(file_path, lines=True)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "U9g64FX7qcWq",
        "outputId": "972d89e7-6042-411b-dd1d-3b2d94dfefa7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      level  seed  episode  step  \\\n",
              "0         5    10        0     0   \n",
              "1         5    10        0     1   \n",
              "2         5    10        0     2   \n",
              "3         5    10        0     3   \n",
              "4         5    10        0     4   \n",
              "...     ...   ...      ...   ...   \n",
              "3073      7    46        7     3   \n",
              "3074      7    46        7     4   \n",
              "3075      7    46        7     5   \n",
              "3076      7    46        7     6   \n",
              "3077      7    46        7     7   \n",
              "\n",
              "                                              input_ids  prompt_len  \\\n",
              "0     [128000, 128000, 128006, 9125, 128007, 271, 38...         452   \n",
              "1     [128000, 128000, 128006, 9125, 128007, 271, 38...         526   \n",
              "2     [128000, 128000, 128006, 9125, 128007, 271, 38...         514   \n",
              "3     [128000, 128000, 128006, 9125, 128007, 271, 38...         485   \n",
              "4     [128000, 128000, 128006, 9125, 128007, 271, 38...         484   \n",
              "...                                                 ...         ...   \n",
              "3073  [128000, 128000, 128006, 9125, 128007, 271, 38...         537   \n",
              "3074  [128000, 128000, 128006, 9125, 128007, 271, 38...         506   \n",
              "3075  [128000, 128000, 128006, 9125, 128007, 271, 38...         556   \n",
              "3076  [128000, 128000, 128006, 9125, 128007, 271, 38...         570   \n",
              "3077  [128000, 128000, 128006, 9125, 128007, 271, 38...         570   \n",
              "\n",
              "      logprob_old                                 tokenwise_logprobs  \\\n",
              "0      -29.546875  [-13.6953125, -4.18359375, -22.375, -12.671875...   \n",
              "1      -36.250000  [-13.6953125, -4.18359375, -22.375, -12.671875...   \n",
              "2      -49.125000  [-13.6953125, -4.18359375, -22.375, -12.671875...   \n",
              "3      -47.437500  [-13.6953125, -4.18359375, -22.375, -12.671875...   \n",
              "4      -33.718750  [-13.6953125, -4.18359375, -22.375, -12.671875...   \n",
              "...           ...                                                ...   \n",
              "3073   -45.843750  [-13.703125, -4.18359375, -22.34375, -12.65625...   \n",
              "3074   -59.531250  [-13.6953125, -4.18359375, -22.375, -12.671875...   \n",
              "3075   -34.718750  [-13.703125, -4.18359375, -22.34375, -12.65625...   \n",
              "3076   -46.031250  [-13.703125, -4.18359375, -22.34375, -12.65625...   \n",
              "3077   -30.578125  [-13.6953125, -4.18359375, -22.375, -12.671875...   \n",
              "\n",
              "      advantage  reward  mean_reward  \n",
              "0      0.063250    0.81      0.78625  \n",
              "1      0.063250    0.81      0.78625  \n",
              "2      0.063250    0.81      0.78625  \n",
              "3      0.063250    0.81      0.78625  \n",
              "4      0.063250    0.81      0.78625  \n",
              "...         ...     ...          ...  \n",
              "3073   0.556319    0.92      0.90125  \n",
              "3074   0.556319    0.92      0.90125  \n",
              "3075   0.556319    0.92      0.90125  \n",
              "3076   0.556319    0.92      0.90125  \n",
              "3077   0.556319    0.92      0.90125  \n",
              "\n",
              "[3078 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b704d8fb-3561-4acd-be27-6ba20008fd47\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>level</th>\n",
              "      <th>seed</th>\n",
              "      <th>episode</th>\n",
              "      <th>step</th>\n",
              "      <th>input_ids</th>\n",
              "      <th>prompt_len</th>\n",
              "      <th>logprob_old</th>\n",
              "      <th>tokenwise_logprobs</th>\n",
              "      <th>advantage</th>\n",
              "      <th>reward</th>\n",
              "      <th>mean_reward</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[128000, 128000, 128006, 9125, 128007, 271, 38...</td>\n",
              "      <td>452</td>\n",
              "      <td>-29.546875</td>\n",
              "      <td>[-13.6953125, -4.18359375, -22.375, -12.671875...</td>\n",
              "      <td>0.063250</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.78625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[128000, 128000, 128006, 9125, 128007, 271, 38...</td>\n",
              "      <td>526</td>\n",
              "      <td>-36.250000</td>\n",
              "      <td>[-13.6953125, -4.18359375, -22.375, -12.671875...</td>\n",
              "      <td>0.063250</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.78625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>[128000, 128000, 128006, 9125, 128007, 271, 38...</td>\n",
              "      <td>514</td>\n",
              "      <td>-49.125000</td>\n",
              "      <td>[-13.6953125, -4.18359375, -22.375, -12.671875...</td>\n",
              "      <td>0.063250</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.78625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>[128000, 128000, 128006, 9125, 128007, 271, 38...</td>\n",
              "      <td>485</td>\n",
              "      <td>-47.437500</td>\n",
              "      <td>[-13.6953125, -4.18359375, -22.375, -12.671875...</td>\n",
              "      <td>0.063250</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.78625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>[128000, 128000, 128006, 9125, 128007, 271, 38...</td>\n",
              "      <td>484</td>\n",
              "      <td>-33.718750</td>\n",
              "      <td>[-13.6953125, -4.18359375, -22.375, -12.671875...</td>\n",
              "      <td>0.063250</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.78625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3073</th>\n",
              "      <td>7</td>\n",
              "      <td>46</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>[128000, 128000, 128006, 9125, 128007, 271, 38...</td>\n",
              "      <td>537</td>\n",
              "      <td>-45.843750</td>\n",
              "      <td>[-13.703125, -4.18359375, -22.34375, -12.65625...</td>\n",
              "      <td>0.556319</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.90125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3074</th>\n",
              "      <td>7</td>\n",
              "      <td>46</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>[128000, 128000, 128006, 9125, 128007, 271, 38...</td>\n",
              "      <td>506</td>\n",
              "      <td>-59.531250</td>\n",
              "      <td>[-13.6953125, -4.18359375, -22.375, -12.671875...</td>\n",
              "      <td>0.556319</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.90125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3075</th>\n",
              "      <td>7</td>\n",
              "      <td>46</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>[128000, 128000, 128006, 9125, 128007, 271, 38...</td>\n",
              "      <td>556</td>\n",
              "      <td>-34.718750</td>\n",
              "      <td>[-13.703125, -4.18359375, -22.34375, -12.65625...</td>\n",
              "      <td>0.556319</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.90125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3076</th>\n",
              "      <td>7</td>\n",
              "      <td>46</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>[128000, 128000, 128006, 9125, 128007, 271, 38...</td>\n",
              "      <td>570</td>\n",
              "      <td>-46.031250</td>\n",
              "      <td>[-13.703125, -4.18359375, -22.34375, -12.65625...</td>\n",
              "      <td>0.556319</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.90125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3077</th>\n",
              "      <td>7</td>\n",
              "      <td>46</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>[128000, 128000, 128006, 9125, 128007, 271, 38...</td>\n",
              "      <td>570</td>\n",
              "      <td>-30.578125</td>\n",
              "      <td>[-13.6953125, -4.18359375, -22.375, -12.671875...</td>\n",
              "      <td>0.556319</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.90125</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3078 rows √ó 11 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b704d8fb-3561-4acd-be27-6ba20008fd47')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b704d8fb-3561-4acd-be27-6ba20008fd47 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b704d8fb-3561-4acd-be27-6ba20008fd47');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-84c11c8b-707a-4369-a4e4-872212c080e5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-84c11c8b-707a-4369-a4e4-872212c080e5')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-84c11c8b-707a-4369-a4e4-872212c080e5 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_f57ed615-5112-4a8a-96c7-0bf8e237c1ac\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f57ed615-5112-4a8a-96c7-0bf8e237c1ac button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3078,\n  \"fields\": [\n    {\n      \"column\": \"level\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 5,\n        \"max\": 7,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          5,\n          6,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"seed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11,\n        \"min\": 10,\n        \"max\": 46,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          42,\n          14,\n          30\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"episode\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 7,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1,\n          5,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"step\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 0,\n        \"max\": 19,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0,\n          17,\n          15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"input_ids\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prompt_len\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 37,\n        \"min\": 443,\n        \"max\": 611,\n        \"num_unique_values\": 140,\n        \"samples\": [\n          581,\n          546,\n          536\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"logprob_old\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11.066665694695905,\n        \"min\": -99.5625,\n        \"max\": -14.8203125,\n        \"num_unique_values\": 1336,\n        \"samples\": [\n          -54.6875,\n          -25.953125,\n          -25.765625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokenwise_logprobs\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"advantage\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0246050621485303,\n        \"min\": -2.639479398727417,\n        \"max\": 2.645751237869262,\n        \"num_unique_values\": 126,\n        \"samples\": [\n          0.613089978694915,\n          0.8528305292129511,\n          0.39485055208206105\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reward\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5432178119834656,\n        \"min\": -0.2,\n        \"max\": 0.9500000000000001,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          0.81,\n          0.929999999999999,\n          0.87\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean_reward\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.34887998542128074,\n        \"min\": -0.20000001788139302,\n        \"max\": 0.923749983310699,\n        \"num_unique_values\": 29,\n        \"samples\": [\n          -0.065000005066394,\n          0.9175000190734861,\n          0.6387500166893001\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NLQjAibnuOlj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNJjk+Dfm0ZL8NNsw5kSGzT",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}